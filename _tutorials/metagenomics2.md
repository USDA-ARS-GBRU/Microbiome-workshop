---
title: "Metagenomics tutorial Part 2: annotation, binning and analysis"
excerpt: "An example workflow for assembly based metagenomics using Anvi'o"
layout: single
author: "Adam Rivers"
---

{% include toc %}


This Part 2 of an assembly-based metagenome tutorial. This is a modified version
of the [Anvi'o metagenome tutorial](http://merenlab.org/2016/06/22/anvio-tutorial-v2/#preparation)
written by A. Murat Eren (Meren) and modified with permission by Adam Rivers.



# Using Anvi'o

Anvi'o is a Python package that runs a web server for interactive visualization.
While Anvi'o is available on Ceres for computationally intensive steps, Anvi'o on
Ceres cannot currently open a web application to explore the data interactively but it can export static HTML that can be viewed locally.

On the [software page](https://usda-ars-gbru.github.io/Microbiome-workshop/tutorials/software)
there are instructions for setting up Anvi'o locally using Docker a container management program.

At this point we recommend running the tutorial locally so that visualization can be used

The first step to do this is start up the docker instance of Anvi'o.

```bash
docker run -p 8080:8080 -it meren/anvio:latest
```

Docker applications are isolated from the rest of your computer. In order to pass
files to application running in Docker containers you need to "bind" i to a location on
your hard drive.

Let’s assume the data you would like to analyze using anvi’o is in a directory at /home/user.name/metagenome2/. To have access to this directory from within the docker image, you can bind it to a directory in the virtual environment. Let’s assume, we want to have access to the content of /home/user.name/metagenome2/, from /metagenome2 directory from within the docker image:

```bash
docker run --rm -v /home/user.name/metagenome2/:/metagenome2 -it meren/anvio:latest
```
Okay now we are ready to start using Anvi'o version 2.4.0.

The goal of this tutorial is to provide a brief overview of the anvi'o workflow for the analysis of assembly-based shotgun metagenomic data. Throughout this tutorial you will primarily learn about the following topics:

* Process your contigs,

* Profile your metagenomic samples and merge them,

* Visualize your data, identify and/or refine genome bins interactively, and create summaries of your results.

---

Help is available from [the Anvi'o discussion group](https://groups.google.com/forum/#!forum/anvio/home), or open an <a href="https://github.com/meren/anvio/issues">issue</a>. Regardless of the method to connect, please don't forget to copy-paste the `anvi-interactive -v` output, the operating system you are using, or any other details that may be relevant to the problem.

# Data sets in this tutorial

In part 2 we will use a dataset of contigs and mapping files derived from a human gut microbiome project.

File |Ceres path | Description
-----|-----|------------
contigs.fa | /project/microbiome_workshop/metagenome/anvio/contigs.fa | co-assembled contigs
[SAMPLE-01-RAW.bam](https://usda-ars-gbru.github.io/Microbiome-workshop/assets/microbiome/SAMPLE-01-RAW.bam)| /project/microbiome_workshop/metagenome/anvio/SAMPLE-01-RAW.bam | Sample 1 mapped to contigs
[SAMPLE-02-RAW.bam](https://usda-ars-gbru.github.io/Microbiome-workshop/assets/microbiome/SAMPLE-02-RAW.bam) | /project/microbiome_workshop/metagenome/anvio/SAMPLE-02-RAW.bam | Sample 2 mapped to contigs
[SAMPLE-03-RAW.bam](https://usda-ars-gbru.github.io/Microbiome-workshop/assets/microbiome/SAMPLE-03-RAW.bam) | /project/microbiome_workshop/metagenome/anvio/SAMPLE-03-RAW.bam | Sample 3 mapped to contigs

{:.notice}
To make things easier to follow, we will use three mock samples throughout this tutorial: `SAMPLE-01`, `SAMPLE-02`, and `SAMPLE-03` (in fact are subsampled from a human gut metagenome time series). By clicking the following links, you can download the `contigs.fa` and the three BAM files we generated by mapping short reads from each sample to `contigs.fa`: [contigs.fa](https://raw.githubusercontent.com/meren/anvio/master/tests/sandbox/contigs.fa), [SAMPLE-01-RAW.bam](https://github.com/meren/anvio/raw/master/tests/sandbox/SAMPLE-01-RAW.bam), [SAMPLE-02-RAW.bam](https://github.com/meren/anvio/raw/master/tests/sandbox/SAMPLE-02-RAW.bam), [SAMPLE-03-RAW.bam](https://github.com/meren/anvio/raw/master/tests/sandbox/SAMPLE-03-RAW.bam). Save them into a directory, and run every command in that directory throughout the tutorial.

For the contigs and BAM files for your *real data*, there is one more thing you have to make sure you have: *simple deflines*. Keep reading.
## Take a look at your FASTA file

**Your FASTA file must have simple deflines**, and if it doesn't have simple deflines, **you must fix your FASTA file prior to mapping**. This is necessary, because the names in `contigs.fa` **must** match the names in your BAM files. Unfortunately, different mapping software behave differently when they find a space character, or say a `|` character in your FASTA file, and they proceed to change those characters in arbitrary ways. Therefore it is essential to keep the sequence IDs in your FASTA file **as simple as possible** before mapping. To avoid any problems later, take a look at your deflines prior to mapping now, and remove anything that is not a digit, an ASCII letter, an underscore, or a dash character.

Here are some bad deflines:

```bash
>Contig-123 length:4567
>Another defline 42
>gi|478446819|gb|JN117275.2|
```

And here are some OK ones:

```bash
>Contig-123
>Another_defline_42
>gi_478446819_gb_JN117275_2
```


If you have bad deflines, you need to reformat your FASTA file, and do the mapping again (if you have done you mapping already, you can convert your BAM files into SAM files, edit the SAM file to correct deflines, and re-generate your BAM files with proper names, but these kind of error-prone hacks require a lot of attention to make sure you did not introduce a bug early on to your precious data).

## Re-formatting your input FASTA

You can use the following anvi'o script to fix your deflines:

```bash
anvi-script-reformat-fasta contigs.fa -o contigs-fixed.fa -l 0 --simplify-names
```

This script will give you your FASTA file with simplified deflines. If you use the flag `--report-file`, it will also create a TAB-delimited file for you to keep track of which defline in the new file corresponds to which defline in the original file. While you are here, it may also be a good idea to remove some very short contigs from your contigs file for a clean start. If you like that idea, you can run the same command this way to also remove sequences that are shorter than 1,000 nts:

```bash
anvi-script-reformat-fasta contigs.fa -o contigs-fixed.fa -l 1000 --simplify-names
```

Let's just overwrite the `contigs.fa` with `contigs-fixed.fa` here to make things simpler:

```bash
mv contigs-fixed.fa contigs.fa
```

# Creating an anvi'o contigs database

An anvi'o contigs database will keep all the information related to your contigs: positions of open reading frames, k-mer frequencies for each contigs, where splits start and end, functional and taxonomic annotation of genes, etc. The contigs database is an essential component of everything related to anvi'o metagenomic workflow.

## Create the database

The following is the simplest way of creating a contigs database:

```bash
anvi-gen-contigs-database -f contigs.fa -o contigs.db
```

When you run this command, `anvi-gen-contigs-database` will,

* **Compute k-mer frequencies** for each contig (the default is `4`, but you can change it using `--kmer-size` parameter if you feel adventurous).

* **Soft-split contigs** longer than 20,000 bp into smaller ones (you can change the split size using the `--split-length`). When gene calling step is not skipped, the process splitting contigs will consider where genes are and avoid cutting genes in the middle. For very very large assemblies this process can take a while, and you can skip it with `--skip-mindful-splitting` flag.

* **Identify open reading frames** using [Prodigal](http://prodigal.ornl.gov/), the bacterial and archaeal gene finding program developed at Oak Ridge National Laboratory and the University of Tennessee. If you don't want gene calling to be done, you can use the flag `--skip-gene-calling` to skip it.  Genes are indexed to start at 0 rather than 1, a convention in Python.

Almost every anvi'o program comes with a help menu that explains available parameters in detail. Don't forget to check them once in a while. If something is not clearly explained, please let us know so we can fix that:

```bash
anvi-gen-contigs-database --help
```

Once you have your contigs database, you can start importing things into it, or directly go to the profiling step.

## Add HMM data

Although this is absolutely optional, you shouldn't skip this step. Anvi'o can do a lot with hidden Markov models ([HMMs](https://en.wikipedia.org/wiki/Hidden_Markov_model) provide statistical means to model complex data in probabilistic terms that can be used to search for patterns, which works beautifully in bioinformatics where we create models from known sequences, and then search for those patterns rapidly in a pool of unknown sequences to recover hits). To decorate your contigs database with hits from HMM models that ship with the platform (which, at this point, constitute multiple published bacterial single-copy gene collections), run this command:

```bash
anvi-run-hmms -c contigs.db
```

When you run this command (without any other parameters),

* It will utilize multiple default bacterial single-copy core gene collections and identify hits among your genes to those collections using HMMER. If you have already run this once, and now would like to add an HMM profile of your own, that is easy. You can use `--hmm-profile-dir` parameter to declare where should anvi'o look for it.

* Note that the program will use only one CPU by default, especially if you have multiple of them available to you, you should use the `--num-threads` parameter. It significantly improves the runtime, since [HMMER](http://hmmer.org/) is truly an awesome software.

## Add taxonomy data
Annotating genes with taxonomy makes things downstream much more meaningful, and improves the human guided binning and refinement steps later on.

Anvio can import taxonomy data from any program using the tabular data format listed [here](http://merenlab.org/2016/06/18/importing-taxonomy/)

For this tutorial  we will be using Anvio's prefered software, [Centrifuge](https://doi.org/10.1101/gr.210641.116)

Assuming you generated an anvi’o contigs database. To import taxonomy into this contigs database, first you will export all gene calls:

```bash
anvi-get-dna-sequences-for-gene-calls -c CONTIGS.db -o gene-calls.fa
```
Then you will run the following command:
```bash
centrifuge -f -x $CENTRIFUGE_BASE/p+h+v/p+h+v gene-calls.fa -S centrifuge_hits.tsv
```
If the environment variable $CENTRIFUGE_BASE is not properly set, you will get an error. See the export instructions here to try again.
{: .notice--info}

---
